{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Acquisition & Preparation\n",
    "\n",
    "In this lesson, we'll be acquiring and preparing some data from our SQL database.\n",
    "\n",
    "## Learning Goals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "    \n",
    "- Acquire a sample of data from SQL.\n",
    "- Identify null values, which nulls are 'deal-breakers', i.e. rows removed, which nulls should be represented by 0, and which should be replaced by a value from other methods, such as mean.\t\t\n",
    "- Identify outliers and decide what to do with them, if anything (remove, keep as-is, replace).\n",
    "- Data Structure: Aggregate as needed so that every row is an observation and each column is a variable (1 variable and not a measure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regular imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import env\n",
    "# from acquire import get_mallcustomer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from our acquire.py:\n",
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    \n",
    "def get_mallcustomer_data():\n",
    "    df = pd.read_sql('SELECT * FROM customers;', get_connection('mall_customers'))\n",
    "    return df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_mallcustomer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire & Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we get a summarization of our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summary of data:\n",
    "# .head()\n",
    "# .info()\n",
    "# .describe()\n",
    "# value_counts() *spread of data\n",
    "# observe nulls in the dataframe\n",
    "#      deal with nulls accordingly:\n",
    "#      -fillna(0)\n",
    "#      -fillna(value/mean/mode)//sklearn.imputer(only after split)\n",
    "#      -drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nulls_by_col(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    rows = df.shape[0]\n",
    "    prcnt_miss = num_missing / rows * 100\n",
    "    cols_missing = pd.DataFrame({'num_rows_missing': num_missing, 'percent_rows_missing': prcnt_miss})\n",
    "    return cols_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_by_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas axes:\n",
    "# rows: r0ws\n",
    "# cols: co1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nulls_by_row(df):\n",
    "    num_missing = df.isnull().sum(axis=1)\n",
    "    prcnt_miss = num_missing / df.shape[1] * 100\n",
    "    rows_missing = pd.DataFrame({'num_cols_missing': num_missing, 'percent_cols_missing': prcnt_miss})\\\n",
    "    .reset_index()\\\n",
    "    .groupby(['num_cols_missing', 'percent_cols_missing']).count()\\\n",
    "    .rename(index=str, columns={'customer_id': 'num_rows'}).reset_index()\n",
    "    return rows_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nulls_by_row(df).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    '''\n",
    "    summarize will take in a single argument (a pandas dataframe) \n",
    "    and output to console various statistics on said dataframe, including:\n",
    "    # .head()\n",
    "    # .info()\n",
    "    # .describe()\n",
    "    # value_counts()\n",
    "    # observation of nulls in the dataframe\n",
    "    '''\n",
    "    print('=====================================================\\n\\n')\n",
    "    print('Dataframe head: ')\n",
    "    print(df.head(3).to_markdown())\n",
    "    print('=====================================================\\n\\n')\n",
    "    print('Dataframe info: ')\n",
    "    print(df.info())\n",
    "    print('=====================================================\\n\\n')\n",
    "    print('Dataframe Description: ')\n",
    "    print(df.describe().to_markdown())\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'O']\n",
    "    cat_cols = [col for col in df.columns if col not in num_cols]\n",
    "    print('=====================================================')\n",
    "    print('DataFrame value counts: ')\n",
    "    for col in df.columns:\n",
    "        if col in cat_cols:\n",
    "            print(df[col].value_counts())\n",
    "        else:\n",
    "            print(df[col].value_counts(bins=10, sort=False))\n",
    "    print('=====================================================')\n",
    "    print('nulls in dataframe by column: ')\n",
    "    print(nulls_by_col(df))\n",
    "    print('=====================================================')\n",
    "    print('nulls in dataframe by row: ')\n",
    "    print(nulls_by_row(df))\n",
    "    print('=====================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical // practical removal of nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_columns(df, cols_to_remove):\n",
    "    df = df.drop(columns=cols_to_remove)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_columns=0.5, prop_required_row=0.75):\n",
    "    threshold = int(round(prop_required_columns * len(df.index), 0))\n",
    "    df = df.dropna(axis=1, thresh=threshold)\n",
    "    threshold = int(round(prop_required_row * len(df.columns), 0))\n",
    "    df = df.dropna(axis=0, thresh=threshold)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combining everything in a cleaning function:\n",
    "\n",
    "def data_prep(df, cols_to_remove=[], prop_required_column=0.5, prop_required_row=0.75):\n",
    "    df = remove_columns(df, cols_to_remove)\n",
    "    df = handle_missing_values(df, prop_required_column, prop_required_row)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = data_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handling Outliers:\n",
    "# note your use-case! (handle outliers approrpriately. \n",
    "# ( Do we want to drop them? )\n",
    "# z-score: appropriate for normal data, based on normal distribution\n",
    "# Tukey: utilizing fences with inner quartile range, not contingent on normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to utilize tukeys method:\n",
    "# calculate iqr:\n",
    "# get Q3 and Q1, get difference (q3 - q1)\n",
    "# establish fences: \n",
    "## standard inner fence: 1.5\n",
    "## standard outer fence: 3\n",
    "# upper bound: q3 + k * iqr\n",
    "# lower bound: q1 - k * iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_upper_outliers(s, k=1.5):\n",
    "    q1, q3 = s.quantile([.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + k * iqr\n",
    "    return s.apply(lambda x: max([x - upper_bound, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_upper_outlier_columns(df, k=1.5):\n",
    "    for col in df.select_dtypes('number'):\n",
    "        df[col + '_outliers_upper'] = get_upper_outliers(df[col], k)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = add_upper_outlier_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outlier_cols = [col for col in df.columns if col.endswith('_outliers_upper')]\n",
    "for col in outlier_cols:\n",
    "    print(col, ': ')\n",
    "    subset = df[col][df[col] > 0]\n",
    "    print(subset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have:\n",
    "# in an organized fashion:\n",
    "# acquired our data\n",
    "# examined the structure and integrity of the data\n",
    "# we hav observed descriptive statistics (univariate)\n",
    "# we have examined null values in a nuanced fashion\n",
    "# we have examined where our outliers live and assessed how we want to approach them\n",
    " # (Takeaway: our outliers exist in income, they appear to be valid and I will not \n",
    "    # drop them at this time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
